[
     {
          "algorithm": "The new algorithm assigns scores to the bins based on a combination of the inverse logarithm of the rest capacity of each bin, a penalty factor that accounts for the square of the ratio of the item size to the rest capacity of each bin divided by the maximum item size, and a scaling factor based on the square of the deviation of the rest capacities from the average rest capacity of all bins. The final scores are adjusted to ensure self-consistency by normalizing them to the sum of the adjusted scores.",
          "code": "import numpy as np\n\ndef score(item: int, bins: np.ndarray) -> np.ndarray:\n    # Calculate the inverse logarithm of the rest capacity of each bin\n    inverse_log_bins = 1 / np.log(bins)\n    \n    # Calculate the square of the ratio of the item size to the rest capacities of each bin\n    ratio = item / bins\n    ratio_squared = np.square(ratio)\n    \n    # Calculate the penalty factor based on the ratio squared divided by the maximum item size\n    penalty_factor = ratio_squared / np.max(ratio_squared)\n    \n    # Calculate the square of the deviation of the rest capacities from the average capacity\n    avg_capacity = np.mean(bins)\n    deviation = np.abs(bins - avg_capacity)\n    deviation_squared = np.square(deviation)\n    \n    # Calculate the scaling factor based on the deviation squared\n    scaling_factor = 1 + deviation_squared / np.max(deviation_squared)\n    \n    # Calculate the adjusted scores based on the inverse logarithm of the bins, the penalty factor, and the scaling factor\n    adjusted_scores = inverse_log_bins * penalty_factor * scaling_factor\n    \n    # Normalize the adjusted scores to ensure self-consistency\n    scores = adjusted_scores / np.sum(adjusted_scores)\n    \n    return scores",
          "objective": 0.03984,
          "other_inf": null
     }
]