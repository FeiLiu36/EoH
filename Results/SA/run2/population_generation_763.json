[
     {
          "algorithm": "\nThe new algorithm assigns scores to the bins based on a combination of the square root of the rest capacity of each bin, a penalty factor that accounts for the cube of the ratio of the item size to the rest capacity of each bin divided by the maximum item size, and a scaling factor based on the cube of the deviation of the rest capacities from the average rest capacity of all bins. The final scores are adjusted to ensure self-consistency by normalizing them to the sum of the adjusted scores.\n",
          "code": "import numpy as np\n\ndef score(item: int, bins: np.ndarray) -> np.ndarray:\n    # Calculate the square root of the rest capacity of each bin\n    sqrt_bins = np.sqrt(bins)\n    \n    # Calculate the cube of the ratio of the item size to the rest capacities of each bin\n    ratio = item / bins\n    ratio_cubed = np.power(ratio, 3)\n    \n    # Calculate the penalty factor based on the ratio cubed divided by the maximum item size\n    penalty_factor = ratio_cubed / np.max(ratio_cubed)\n    \n    # Calculate the cube of the deviation of the rest capacities from the average capacity\n    avg_capacity = np.mean(bins)\n    deviation = np.abs(bins - avg_capacity)\n    deviation_cubed = np.power(deviation, 3)\n    \n    # Calculate the scaling factor based on the deviation cubed\n    scaling_factor = 1 + deviation_cubed / np.max(deviation_cubed)\n    \n    # Calculate the adjusted scores based on the square root of the bins, the penalty factor, and the scaling factor\n    adjusted_scores = sqrt_bins * penalty_factor * scaling_factor\n    \n    # Normalize the adjusted scores to ensure self-consistency\n    scores = adjusted_scores / np.sum(adjusted_scores)\n    \n    return scores",
          "objective": 0.03984,
          "other_inf": null
     }
]