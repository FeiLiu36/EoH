

<div align=center>
<h1 align="center">
EoH: Evolution of Heuristics 
</h1>
<h5 align="center">
è¿›åŒ–è®¡ç®—+å¤§æ¨¡å‹ è‡ªåŠ¨ç®—æ³•è®¾è®¡å¹³å°
</h5>

 [English Version è‹±æ–‡ç‰ˆæœ¬](./README.md)

[![Github][Github-image]][Github-url]
[![License][License-image]][License-url]
[![Releases][Releases-image]][Releases-url]
[![Wiki][Wiki-image]][Wiki-url]


[Github-image]: https://img.shields.io/badge/github-12100E.svg?style=flat-square
[License-image]: https://img.shields.io/badge/License-MIT-orange?style=flat-square
[Releases-image]: https://img.shields.io/badge/Release-Version_1.0-blue?style=flat-square
[Installation-image]: https://img.shields.io/badge/Web_Demo-Version_1.0-blue?style=flat-square
[Wiki-image]: https://img.shields.io/badge/Docs-å‚è€ƒæ–‡æ¡£-black?style=flat-square


[Github-url]: https://github.com/FeiLiu36/EOH
[License-url]: https://github.com/FeiLiu36/EOH/blob/main/LICENSE
[Releases-url]: https://github.com/FeiLiu36/EOH/releases
[Wiki-url]: https://github.com/FeiLiu36/EOH/tree/main/docs



</div>
<br>



**æ¼”å˜è®¡ç®—** + **å¤§å‹è¯­è¨€æ¨¡å‹**çš„å¹³å°ï¼Œç”¨äºè‡ªåŠ¨ç®—æ³•è®¾è®¡ã€‚

<img src="./docs/figures/eoh.JPG" alt="eoh" width="600" height="280">

---
##  æ–°é—»  ğŸ”¥ 

+ 2024.5.5 [L-AutoDA: Leveraging Large Language Models for Automated Decision-based Adversarial Attacks](https://arxiv.org/abs/2401.15335) å·²è¢« **GECCO 2024** å½•ç”¨äº†! ğŸ‰
+ 2024.5.2 [EoH (Evolution of Heuristics: Towards Efficient Automatic Algorithm Design using Large Language Model)](https://arxiv.org/abs/2401.02051) å·²è¢« **ICML 2024** å½•ç”¨äº†ï¼ğŸ‰

---

## ç®€ä»‹


å¯å‘å¼ç®—æ³•åœ¨è§£å†³å¤æ‚çš„æœç´¢å’Œä¼˜åŒ–é—®é¢˜æ—¶æ˜¯ä¸å¯æˆ–ç¼ºçš„ã€‚ç„¶è€Œï¼Œæ‰‹åŠ¨å¯å‘å¼è®¾è®¡æ˜¯ç¹ççš„ï¼Œéœ€è¦å¤§é‡çš„äººç±»ç›´è§‰å’Œç»éªŒã€‚

EOHå¼•å…¥äº†ä¸€ç§æ–°çš„èŒƒå¼ï¼Œåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œæ¼”å˜è®¡ç®—ï¼ˆECï¼‰ä¹‹é—´çš„ååŒä½œç”¨è¿›è¡Œè‡ªåŠ¨å¯å‘å¼è®¾è®¡ï¼ˆAHDï¼‰ã€‚æ€ç»´å’Œä»£ç åœ¨æ¼”å˜æ¡†æ¶å†…çš„å…±åŒæ¼”åŒ–ä¸ºå“è¶Šçš„AHDæ€§èƒ½ï¼ŒåŒæ—¶é™ä½äº†è®¡ç®—æˆæœ¬ã€‚

<img src="./docs/figures/evolution.jpg" alt="eoh" width="1000" height="auto">

EOHåœ¨åˆ†é’Ÿ/å°æ—¶å†…è®¾è®¡å‡ºäº†éå¸¸æœ‰ç«äº‰åŠ›çš„ç®—æ³•/å¯å‘å¼æ–¹æ³•ã€‚ä¾‹å¦‚ï¼Œåœ¨åœ¨çº¿è£…ç®±é—®é¢˜ä¸Šï¼ŒEoHè‡ªåŠ¨è®¾è®¡å‡ºæ–°çš„æœ€ä¼˜å¯å‘å¼ç®—æ³•ï¼Œä¼˜äºäººå·¥è®¾è®¡ç®—æ³•å’ŒåŒæœŸè°·æ­Œå·¥ä½œFunSearchã€‚

ä¸‹å›¾æ˜¾ç¤ºäº†åœ¨åœ¨çº¿è£…ç®±é—®é¢˜ä¸ŠEOHçš„æ¼”å˜ã€‚æˆ‘ä»¬æ¦‚è¿°äº†åœ¨æ¼”å˜è¿‡ç¨‹ä¸­å¯¹æœ€ä½³ç»“æœæœ‰æ‰€è´¡çŒ®çš„å…³é”®**æ€æƒ³**å’Œç›¸åº”çš„**ä»£ç **ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ ‡è®°äº†å¯¼è‡´æ”¹è¿›çš„æç¤ºç­–ç•¥ã€‚æœ€åï¼Œæˆ‘ä»¬å±•ç¤ºäº†æœ€ç»ˆç§ç¾¤ä¸­çš„æœ€ä¼˜å¯å‘å¼æ–¹æ³•ï¼Œå¹¶å°†å…¶ä¸äººç±»è®¾è®¡çš„å¯å‘å¼æ–¹æ³•å’Œæ¥è‡ªFunSearchçš„å¯å‘å¼æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒã€‚

<img src="./docs/figures/evolution.jpg" alt="ael" width="1000" height="auto">



å¦‚æœæ‚¨å‘ç°EoHå¯¹æ‚¨çš„ç ”ç©¶æˆ–åº”ç”¨é¡¹ç›®æœ‰æ‰€å¸®åŠ©ï¼š

```bibtex
@inproceedings{fei2024eoh,
    title={å¯å‘å¼çš„æ¼”å˜ï¼šåˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å®ç°é«˜æ•ˆè‡ªåŠ¨ç®—æ³•è®¾è®¡},
    author={åˆ˜é£ï¼Œä½Ÿä¾ è‰¯ï¼Œè¢æ˜è½©ï¼Œæ—å–œï¼Œç½—ç”«ï¼Œç‹æŒ¯å¤ï¼Œé™†å¿—è¶…ï¼Œå¼ åº†ç¦},
    booktitle={ICML},
    year={2024},
    url={https://arxiv.org/abs/2401.02051}
}
```

å¦‚æœæ‚¨å¯¹LLM4Optæˆ–EoHæ„Ÿå…´è¶£ï¼Œæ‚¨å¯ä»¥ï¼š

+ é€šè¿‡ç”µå­é‚®ä»¶fliu36-c@my.cityu.edu.hkä¸æˆ‘ä»¬è”ç³»ã€‚
+ æ¬¢è¿è®¿é—®[å¤§æ¨¡å‹ä¸ä¼˜åŒ–å‚è€ƒæ–‡çŒ®å’Œç ”ç©¶è®ºæ–‡æ”¶è—](https://github.com/FeiLiu36/LLM4Opt)
+ åŠ å…¥æˆ‘ä»¬çš„è®¨è®ºç»„ï¼ˆå³å°†æ¨å‡ºï¼‰

å¦‚æœæ‚¨åœ¨ä½¿ç”¨ä»£ç æ—¶é‡åˆ°ä»»ä½•å›°éš¾ï¼Œè¯·é€šè¿‡ä¸Šè¿°æ–¹å¼ä¸æˆ‘ä»¬è”ç³»æˆ–æäº¤[é—®é¢˜]ã€‚

## ç³»ç»Ÿè¦æ±‚
+ python >= 3.10
+ numba
+ numpy
+ joblib

## EoHç¤ºä¾‹ç”¨æ³•
ç¬¬1æ­¥ï¼šå®‰è£…EoH
æˆ‘ä»¬å»ºè®®åœ¨å…·æœ‰python>=3.10çš„[conda](https://conda.io/projects/conda/en/latest/index.html)ç¯å¢ƒä¸­å®‰è£…å’Œè¿è¡ŒEoH

```bash
cd eoh

pip install .
```
 
ç¬¬2æ­¥ï¼šå°è¯•ç¤ºä¾‹ï¼š
**åœ¨å¼€å§‹å‰è®¾ç½®æ‚¨çš„ç«¯ç‚¹å’Œå¯†é’¥ä»¥è¿œç¨‹LLMæˆ–åœ¨å¯åŠ¨ä¹‹å‰è®¾ç½®æ‚¨çš„æœ¬åœ°LLMï¼**
```python
from eoh import eoh
from eoh.utils.getParas import Paras

# Parameter initilization #
paras = Paras() 

# Set parameters #
paras.set_paras(method = "eoh",    # ['ael','eoh']
                problem = "bp_online", #['tsp_construct','bp_online']
                llm_api_endpoint = "xxx", # set your LLM endpoint
                llm_api_key = "xxx",   # set your LLM key
                llm_model = "gpt-3.5-turbo-1106",
                ec_pop_size = 5, # number of samples in each population
                ec_n_pop = 5,  # number of populations
                exp_n_proc = 4,  # multi-core parallel
                exp_debug_mode = False)

# initilization
evolution = eoh.EVOL(paras)

# run 
evolution.run()
```

 
###### ç¤ºä¾‹1ï¼šæ—…è¡Œå•†é—®é¢˜çš„æ„é€ ç®—æ³•
```bash
cd examples/tsp_construct

python runEoH.py
```

 
###### ç¤ºä¾‹2ï¼šåœ¨çº¿è£…ç®±é—®é¢˜
ï¼ˆåœ¨æ‚¨çš„ä¸ªäººè®¡ç®—æœºä¸Šåœ¨30åˆ†é’Ÿå†…ç”Ÿæˆæ–°çš„æœ€ä½³å¯å‘å¼æ–¹æ³•å¹¶å‡»è´¥Funsearchï¼ i7-10700 2.9Ghz, 32GBï¼‰

```bash
cd examples/bp_online

python runEoH.py
```
 
###### ç¤ºä¾‹3ï¼šä½¿ç”¨EoHè§£å†³æ‚¨çš„æœ¬åœ°é—®é¢˜
```bash
cd examples/local_problem

python runEoH.py
```
 
### ä½¿ç”¨EoHå¹³å°çš„æ›´å¤šç¤ºä¾‹ï¼ˆä»£ç å’Œè®ºæ–‡ï¼‰
#### ç»„åˆä¼˜åŒ–
+ åœ¨çº¿è£…ç®±é—®é¢˜ (BP)ï¼Œè´ªå©ªå¯å‘å¼æ–¹æ³•ï¼Œä»£ç , [è®ºæ–‡]
+ æ—…è¡Œå•†é—®é¢˜ (TSP)ï¼Œæ„é€ å¯å‘å¼æ–¹æ³•ï¼Œä»£ç , [è®ºæ–‡]
+ æ—…è¡Œå•†é—®é¢˜ (TSP)ï¼Œå¼•å¯¼å¼å±€éƒ¨æœç´¢ï¼Œ[ä»£ç ], [è®ºæ–‡]
+ æµæ°´è½¦é—´è°ƒåº¦é—®é¢˜ï¼ˆFSSPï¼‰ï¼Œå¼•å¯¼å¼å±€éƒ¨æœç´¢ï¼Œ[ä»£ç ], [è®ºæ–‡]
#### æœºå™¨å­¦ä¹ 
+ å›¾åƒæ”»å‡»ï¼Œ[ä»£ç ], [è®ºæ–‡](https://arxiv.org/abs/2401.15335)
#### è´å¶æ–¯ä¼˜åŒ–
+ è·å–å‡½æ•°è‡ªåŠ¨è®¾è®¡ï¼Œ[è®ºæ–‡](https://arxiv.org/abs/2404.16906)
#### æ•°å­¦
+ å¯æ¥å—é›†åˆ
#### ç‰©ç†å­¦
+ è®¡ç®—æµä½“åŠ¨åŠ›å­¦

## åœ¨æ‚¨çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨EoH
æä¾›äº†è¿™é‡Œçš„é€æ­¥æŒ‡å—ï¼ˆå³å°†æ¨å‡ºï¼‰

## å¤§æ¨¡å‹è®¾ç½®
1) è¿œç¨‹LLM + APIï¼ˆä¾‹å¦‚ï¼ŒGPT3.5ï¼ŒGPT4ï¼‰ï¼ˆæ¨èï¼ï¼‰ï¼š
+ OpenAIå®˜æ–¹APIã€‚
+ å…¶ä»–APIï¼š
  + https://yukonnet.site/ (Llama, Llamacode, Gemini Pro, ç­‰)
  + https://github.com/chatanywhere/GPT_API_free
  + https://www.api2d.com/
2) æœ¬åœ°LLMéƒ¨ç½² + APIï¼ˆä¾‹å¦‚ï¼ŒLlamacodeï¼Œinstruct Llamaï¼Œgemmaï¼Œdeepseekç­‰ï¼‰ï¼š
+ ç¬¬1æ­¥ï¼šä¸‹è½½Huggingfaceæ¨¡å‹ï¼Œä¾‹å¦‚ï¼Œä¸‹è½½gemma-2b-itï¼ˆgit clone https://huggingface.co/google/gemma-2b-itï¼‰
+ ç¬¬2æ­¥ï¼š + cd llm_server + python gemma_instruct_server.py
+ ç¬¬3æ­¥ï¼šå°†è¿è¡ŒæœåŠ¡å™¨ç”Ÿæˆçš„urlå¤åˆ¶åˆ°request.pyï¼ˆä¾‹å¦‚ï¼Œå°†url='http://127.0.0.1:11012/completions'è®¾ç½®ä¸ºæµ‹è¯•æ‚¨çš„æœåŠ¡å™¨éƒ¨ç½²)ã€‚
+ ç¬¬4æ­¥ï¼šå°†è¿è¡ŒæœåŠ¡å™¨ç”Ÿæˆçš„urlå¤åˆ¶åˆ°æ‚¨çš„ç¤ºä¾‹ä¸­çš„runAEL.pyä¸­ï¼ˆä¾‹å¦‚ï¼Œå°†url='http://127.0.0.1:11012/completions'è®¾ç½®è¯¥é¡¹ï¼‰ã€‚
+ ç¬¬5æ­¥ï¼šPython runAEL.py
3) è‡ªå·±çš„å®ç°ï¼š
+ å¦‚æœæ‚¨æƒ³ä½¿ç”¨å…¶ä»–LLMæˆ–è‡ªå·±çš„GPT APIæˆ–æœ¬åœ°LLMsï¼Œè¯·åœ¨ael/llmä¸­æ·»åŠ æ‚¨çš„æ¥å£

## å…³äºLLM4Optçš„ç›¸å…³å·¥ä½œ
æ¬¢è¿è®¿é—®[å¤§æ¨¡å‹ä¸ä¼˜åŒ–å‚è€ƒæ–‡çŒ®å’Œç ”ç©¶è®ºæ–‡æ”¶è—](https://github.com/FeiLiu36/LLM4Opt)

## è´¡çŒ®è€…



